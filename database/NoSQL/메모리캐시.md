
# 메모리 캐시
메모리 캐싱 서비스 멤캐시(Memcached)와 레디스(Redis)에 대해 알아 봅시다.  
메모리 캐시 방식이라는 것을 제외하고는 전혀 다른 듯한 두 서비스에 대해 알아 봅시다.  

## 멤키시드(Memcached)
무료로 사용할 수 있는 오픈 소스이며 분산 메모리 캐싱 시스템 입니다.  

멤캐시드를 사용하지 않았을 때는 분리되어 있는 메모리에 대해 각각의 서버에서 사용할 수 있는 것은 할당 된 메모리 크기만큼인데 멤캐시드를 적용할 경우, 논리적으로 결합되어 있기 때문에 각가의 웹 서버는 전체 메모리 캐시 크기만큼의 용량을 사용할 수 있습니다.  

## 레디스(Redis)
잘못쓰면 망한다 !!  

레디스 역시 오픈소스로, in-memory data structure store로 데이터베이스로 사용될 수 있으며 캐시와 메시지 브로커로써 사용될 수 있는 기술입니다.  
Key-Value 타입으로 저장합니다.  
레디스에서는 배포할 경우에는 Linux를 이용하기를 권장하고 있습니다.  

NoSQL 관점에서 봤을 때 Redis는 가장 기본적이고 단순한 구조인 Key-Value 타입을 사용하고 있습니다.  
데이터 모델은 복잡할수록 성능이 저하되므로 Redis는 단순한 구조를 통해 높은 성능을 보장한다고 할 수 있습니다.  

- 데이터 저장소로 가장 입/출력 속도가 빠른 '메모리'를 채택
- 단순한 구조의 데이터 모델인 Key-Value 방식을 통해 빠른 속도를 보장
- 다양한 API 지원

In-Memory-Cache에는 멤캐시,레디스,테라코타,구아바,라이브러리 등이 있습니다.  

Redis는 Global Cache방식을 채택했습니다.  
Global Cache방식은 네트워크 트래픽이 발생하기 때문에 Java Heap 영역에서 조회되는 Local Cache가 성능이 낫지만 WAS 인스턴스가 증가하게 되는 경우, Cache에 저장되는 데이터 크기가 커지고 이럴 수록 Redis 방식이 유리합니다.  

Redis가 주목 받는 이유는 빠른 처리 속도와 검증된 소프트웨어 안정성에 있습니다.  
모든 데이터를 메모리에 상주시켜 처리하고 이벤트 기반의 네트워크 비동기 입출력 처리를 해서, 한 Redis 서버는 초당 수만 건 이상의 요청을 처리할 수 있습니다.   
또한 데이터의 가용성과 영속성을 위해 복제 및 RDB(Redis DB), AOF(Append Only File) 기능을 제공합니다.  

## In-Memory Cache란?

### Local Cache VS Global Cache
현재 Key-Value 방식의 Store Trend에서 Redis가 1위를 차지했고 2위는 Memcached가 차지 했습니다.(2014.3기준)  

Redis는 Stackoverflow, flickr, instagram, github, tumblr, LINE 등의 시스템에 적용 되었습니다.  

메모리 캐시 기반의 제품이 많은 시스템에서 적용되는 이유는 단연 성능상의 이유 때문인데, 캐시 방식을 통해 DB Read 부하를 감소시킬 수 있기 때문입니다.  
Redis는 급격하게 상용자가 집중되는 환경이나 대규모 확장이 예정되어 있는 환경에 적합해 보입니다.  
Global Cache 방식이 적용되어 있기 때문에 WAS 인스턴스 확장이 용이하지만 Cache 및 Redis 세션 등 새로운 관리 포인트가 증가할 수 있다는 점이 단점이라고 할 수 있습니다.  



























---
참조  
[Memcached, Redis : 메모리 캐시](https://ojava.tistory.com/70)
[nBase-ARC: Redis Cluster](https://d2.naver.com/helloworld/614607)
---
참고
[카카오 "레디스, 잘못쓰면 망한다"](http://www.zdnet.co.kr/news/news_view.asp?artice_id=20131119174125)
레디스의 특징은 '싱글 쓰레드'라는 점이다.    
싱글 쓰레드는 1번에 1개의 명령어만 실행할 수 있다. 한 서비스에서 요청된 명령어에 대한 작업이 끝나기 전까진 다른 서비스에서 요청하는 명령을 못 받아들인다.    
이 특성 때문에 레디스로 웹서비스를 관리할 경우 절대 쓰면 안 되는 명령어들이 몇 가지 있다고 한다.   
저장된 모든 키를 보여주는 명령어(keys)나 모든 데이터를 소거하는 명령어(flushall) 등이다.  
모든 키를 보여주거나 플러싱하는 명령어는 테스트 환경이나 소량의 데이터를 관리하는 시스템에서 모니터링하는 용도로만 써야 한다 며 실행 대상을 전수처리하기 때문에 점차 데이터를 쌓아가는 환경에서는 운영에 차질을 빚을 정도로 속도가 느려질 것 이라고 경고했다.  
이어 빠른 속도로 플러시라는 명령어를 지원하는 멤캐시드 때문에 사람들이 레디스에서도 이 명령어가 금방 처리될 거라 기대하기도 하는데 실제 작동하는 방식이 완전히 다르다 며 이 명령어 수행 시간을 재 보면 멤캐시드는 항상 일정하게 1~2ms가 나오는데 레디스는 데이터 100만건 정도 기준으로 1초(1천ms)로 이미 훨씬 느리다, 이건 실패한 사용법 이라고 지적했다.  
레디스는 인메모리DB라 빠른 속도가 강점이지만 큰 용량의 데이터를 담기엔 공간 제약이 크다. 그래서 실시간 처리는 인메모리에서, 보관은 디스크 기반 스토리지로 하는 구조가 성능과 효율을 함께 달성할 수 있다. 트위터, 인스타그램, 페이스북처럼 대규모 사용자 기반을 갖춘 인터넷 서비스 업체들도 이런 식으로 서비스를 설계했다는 설명이다.  
레디스는 32비트 환경에선 최대 3GB 메모리만 사용 가능하고 64비트 시스템에서는 그런 제약이 없어 운영체제(OS)의 가상메모리(스왑)까지 쓴다.  
하지만 이 경우 시스템의 메모리 한계를 인식하지 못해 더 많은 메모리를 요구하다가 문제를 일으킬 수 있어 관리자가 따로 설정을 더해줘야 한다.  
레디스는 멤캐시드에서 지원 안 하는 명령어 '콜렉션'을 지원하지만 앞서 '플러시올'이나 '키즈'같이 싱글쓰레드 방식에서 쓰지 말아야 하는 기능에 해당한다 며 콜렉션에 데이터 100만건을 넣으면 처리시간이 10초, 1천만건 넣으면 100초씩 걸리는 식으로 늘어나기 때문에 굳이 쓰려면 일단 데이터를 1만건 미만으로 관리해야 한다 고 권고했다. 이어 레디스에서 디스크에 메모리 상태를 그대로 받아 저장하는(메모리스냅숏) RDB 기능이 레디스 서버 장애요인 99.9%를 차지한다 며 원한다면 이 기능을 그냥 꺼 둘 수 있다 고 말했다.  
설명에 따르면 아마존 웹서비스 서버 기준으로 60GB짜리 메모리 서버 테스트시 RDB 작업에 10분 정도가 걸린다. 싱글쓰레드 문제를 겪지 않기 위해 'Fork()'라는 분기 기능을 쓸 수 있지만 이 경우 메모리를 2배로 잡아먹어, 용량부족에 따른 오류와 원인을 알수 없는 장애를 낼 수 있다. 이어지는 효과로, RDB 작업이 실패하면 '쓰기 거부' 상태가 돼 추가 장애를 낼 수 있다.  
레디스 시스템에서 슬레이브는 이름처럼 마스터의 데이터 저장을 보조한다. 마스터가 죽었다가 되살아날 때 자신의 정보를 모두 없애고 그 데이터를 그대로 베낀다. 별도 조치 없이 아무 데이터가 없는 마스터를 시스템에 연결하면 슬레이브에 남은 데이터를 마스터에 되살릴 수 없다는 점이 포인트다. 이를 피하려면 복구할 데이터를 가진 시스템에 '슬레이브오브노원'이라는 명령어를 줘서 그걸 마스터로 승격시켜야 한다.  
이런 얘기들을 전하면 (개발자들이) '레디스를 아예 쓰지말라는거 아니냐' 하는데, 이걸 알면 모르는 것보다 더 잘 쓸 수 있게 된다 고 거듭 말했다.  