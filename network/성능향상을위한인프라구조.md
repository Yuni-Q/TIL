
# 성능 향상을 위한 인프라 구조

## 응답과 처리량

### 성능 문제의 두 가지 원인
- 시스템 성능을 가리킬 때 응답(response)과 처리량(throughput)이라는 지표가 자주 사용된다.
  - 응답은 처리 하나당 소요 시간을 의마한다.
  - 처리량은 단위 시간당 처리 하는 양을 의미한다.
  - 실제 시스템에서는 단일 사용자 응답 시간만으로는 부족하기 때문에 여러 사용자의 평균값을 이용한다. 이때 통계학에서 이용되는 퍼센타일 개념을 이용한다. 극단적으로 응답 시간이 긴 사용자는 다른 문제를 내포하고 있기 때문에 오차라고 생각하고 평균값에 포함하지 않는다. 10% 사용자 값을 버리고 나머지 90% 사용자의 평균 응답 시간을 이용하는 형태다.

### 응답 문제
- 모든 응답 시간에는 반드시 물리적 제약이 존재한다.
- 응답 시간 개선에 한계가 보일 때는 처리량 개선을 통해서 시스템 전체 사용률을 개선하는 것이 일반적이다.

### 처리량 문제
- 처리량이란 다수의 요청이 동시에 발생하면 막히기 쉽다.
- 응답과 처리량이 밀렂ㅂ한 관계가 있다. 응답이 매우 느린 시스템에서는 다수의 사용자 요청이 시스템 내에 누적되므로 전체 처리량도 낮아진다. 또한, 처리량이 포화 상태가 되면 리소스가 부족해져서 응답도 함께 악화 된다. 성능 병목 현상을 개선하려면 반드시 양쪽을 고려해서 진행 해야 한다.

## 병목 현상이란?
- 처리량을 제한하고 있는 요인을 가리키며 병(bottle)의 목(neck) 부분을 생각하면 된다.

### CAP 정리
- Consistency(일관성) : 특정 시점에 반드시 동일 데이터가 존재해야 하는 것을 의미한다.
- Availability(가용성) : 하나의 서버가 다운돼도 다른 서버가 처리를 계속하는 것을 가리킨다.
- ParitionTolerance(분할 허용성) : 서버를 늘림으로써 성능을 확장할 수 있는 것을 의미한다.
- 이 중 두가지를 만족하면 마지막 한 가지는 희생해야 한다는 법칙이다.
- RDBMS는 CA : C가 병목지점이다.
- 키-벨류 저장(KVS)은 AP : P가 병목지점이 되기 쉽다.
- 시스템 아키텍처가 CAP 정리를 어느 부분을 중시하는지를 파악해 두면 시스템 구성도만 보고도 병목 지점을 찾아서 개선안을 도출할 수 있다.
- 근거가 되는 자료를 확인한다는 측면에서라도 로그를 잘 확인하는 것이 좋다.

### 병목현상을 어떻게 해결하는가?
- 로그를 취득해서 어느 서버가 병목 지점이 되고 있는지를 찾아내는 것부터 시작해야 한다.
- 해결 방안
  - 첫 번째는 병목 위치를 파악해서 어떻게든 해결하는 것이다. 이것을 튜닝이라고 한다. 튜닝 시에는 병목 위치를 작은 단위로 세분화해서 병목 영역을 더 집중저긍로 파헤치는 접근법이 유효하다. 서버 내에서는 여러 가지 하드웨어와 소프트웨어가 동작하고 있기 때문에 각 컴포넌트의 로그를 확인해 갈 필요가 있다.
  - 다른 한 가지 방법은 시스템 이용자 수를 제한하는 것이다. 이것은 유량 제어라는 이름이 붙어 있을 정도로 매우 직관적인 방법이다. 단, 유량 제어에서는 사용자에게 에러를 반환하는 것이 전부라서 근본적인 해결책은 되지 못한다. 이때는 수평 분할을 통해 서버를 증설함으로써 시스템 전체 허용량을 늘리는 접근법을 병용할 필요가 있다.

### 병목지점은 반드시 존재한다
- 모든 서버, 소프트웨어, 물리 장비가 균등하게 처리량을 분배하는 것은 이론상으로 불가능하기 때문이다.
- 하나의 계층에서 병목 현상이 해결되면 반드시 다른 위치에서 병목 현상이 발생한다.

#### 병목 현상의 숙명의 적, 데이터베이스
- 최종적으로는 DB 서버가 병목 지점이 되는 경우가 대부분이다. 이런 이유로 DB 엔지니어는 매일 같이 튜닝에 시달리고 있다.

## 3계층형 시스템 그림을 통해 본 병목 현상
- CPU 병목 현상
- 메모리 병목 현상
- 디스크 I/O 병목 현상
- 네트워크 I/O 병목 현상
- 애플리케이션 병목 현상

### CPU 병목 현상 예
- 프로세스가 효율적으로 처리를 진행하다 보면 CPU 사용률이 100%가 될 수 있다. 이것은 시스템 관점에서 비효율적인 상태가 아니라 오히려 그 반대다. 이 상태는 다른 계층의 처리량이 매우 좋아서 최종적으로는 CPU에서 병목 현상이 발생한다는 것을 의미하기 때문이다. CPU가 유용하게 활용되고 있어서 시스템 투자 효과가 높다고 CIO(최고 정보 책임자)로부터 칭찬을 받은 것이다. CPU 병목 현상이 있다고 해도 사용자가 만족하고 있다면 이 상태는 아무런 문제가 되지 않는다.
- CPU 사용률은 하나의 상태를 가리키는 지표일 뿐이다. CPU 사용률이 급증해서 문제가 있는지 없는지를 판단 하려면 사용자 관점의 응답 속도나 시스템 전체 처리량을 확인해야 한다. 사용자가 만족하지 못한다면 CPU 사용률이 높은 상태 자체를 문제로 생각하지 말고 근복적인 원인을 조사하도록 하자.
- CPU에 기인한 성능 문제
  - CPU를 이용하는 처리가 많아서  대기 행렬이 발생하고 있다.
  - CPU 응답이 느리다.
- CPU 코어 수를 늘리거나 수평 분할을 통해 서버 수를 늘리는 것을 스케일아웃(scale-out)이라고 한다.
- 응답의 병목 현상
 - 대기 행렬을 듀닝하면 처리량 문제는 해결된다. 하지만 처리량 문제를 해결해도 반드시 응답 문제가 해결되는 것은 아니다.
- 처리 능력을 향상 시킨다. 
  - 첫 번째는 처리 능력을 향상 시키는 방법이다. 이것을 스케일업(scale-up)이라고 한다. 하지만 최근의 CPU는 클럭 차이가 크지 않아서 이를 통한 극적인 개선 효과는 기대하기 어렵다.
- 병렬로 처리 한다.
  - 두 번째는 분할해서 다수의 CPU 코어에게 동시 처리를 시키는 것이다. 병렬화, 멀티 프로세스화, 멀티 스레드화해서 복수의 CPU 코어를 이용함으로써 전체적인 처리 응답 시간을 향상 시킬수 있다.
  - 처리를 병렬화 할 수 있는가가 중요 사항이 된다. 처리에 따라서는 병렬화하는 것이 매우 어려운 경우도 있으며, 병렬화가 안 되는 경우는 CPU 코어 수를 늘리거나 서버를 늘려서 스케일아웃한다고 해도 큰 효과를 보기 어렵다. 벙렬화 검토는 인프라만으로 한계가 있기 때문에 애플리케이션 개발자의 협조가 필요하다.
- CPU 사용률이 오르지 않는다.
  - 대분은 애플리케이션에서는 CPU 사용률이 100%에 도달하는 경우가 거의 없다. 그 전에 디스크 I/O나 네트워크 I/O에서 막히는 경우가 많기 때문이다.
  - 동기 I/O는 시스템 콜로 커널에 명령이 가지만, 이것이 완료되지 않으면 프로세스가 다음 처리를 진행하지 않는다. 이 상태의 프로세스는 대기 상태가 되며, CPU를 이용할 수 없기 때문에 CPU 사용률은 올라가지 않는다. 이런 경우는 CPU 사용률이 낮아도 I/O 대기 큐에서 대기하는 프로세스 수가 증가한다.
  - 애플리케이션이 CPU, 메모리, I/O 등의 하드웨어 리소스를 제대로 활용하지 못하는 것이 문제다.
  - 개선 방법
    - 첫 번째는 처리를 다중화해서 CPU를 적절하게 활용하는 것이다.
    - 다른 한 가지는 I/O를 비동기화 하는 것이다.

### 메모리 병목 현상 예
- 영역 부족에 의한 병목 현상
  - 프로세스가 가동해서 어떤 처리를 하려면 반드시 전용 메모리 영역이 필요하다. 하지만 서버 상의 메모리 영역은 제한돼 있다.
  - 이 제한된 메모리 영역이 부족하지 않도록 OS 커널 츠겡서 페이징(paging) 또는 스와핑(swapping)이라고는 처리를 해서 빈 메모리를 확보하는 구조가 있다. 즉, 부족한 부분은 디스크 영역으로 보완해서 가성적인 메모리가 있다는 것을 보여 주는 기술이다. 가상 메모리(virtual memory)라고 한다.
  - 메모리와 디스크에는 압도적인 성능 차이가 있으므로 조금이라도 디스크에 저장하거나 메모리로 되돌리는 처리가 발생하면 성능 저하가 발생한다. 이것을 허세를 부린 것에 대한 벌이라고 할 수 있다.
- 동일 데이터에 대한 병목 현상
  - 디스크 I/O 시간응ㄹ 단툭하기 위해서는 메모리에 캐시로 데이터를 배치해 두는 것도 일례가 될 수 있다.
  - 메모리에 데이터를 캐시해도 메모리 경ㄹ합이 발생하는 경우도 있다. 메모리 영역에 액세스하는 것은 매우 빠르다. OS의 프로세스나 스레드가 액세스하는 경우, 나노초 단위의 액세스가 된다. 특정 영역을 복수의 프로세스가 공유하는 경우, 메모리 영역을 참조 또는 갱신할 때 누군가가 그 영역을 관리할 필요가 생긴다. 빠른쪽이 이기는 방식은 각각의 프로세스나 스레드가 경합하는 만큼 모두가 사이 좋게 줄을 서 있으면 되는데 관리 영역이 데이터 영역보다 커질 수 있다.
  - 이런 문제를 해결하려면 애초에 경합이 발생하지 않도록 복수의 프로세스나 스레드가 같은 메로리 영역을 참조하지 않도록 만들면 된다.

### 디스크 I/O 병목 현상의 예
- 로컬 디스크, SAN 저장소, 네트워크 저장소
    - 디스크 I/O가 이루어지는 위피는 크세 세 군데다.
        1. 서버 내부의 디스크(로컬 디스크) I/O
        1. Fibre Channel(FC)을 경유하는 Storage Area Network(SAN) 저장소 I/O
        1. 네트워크를 경유한느 Network Attached Storage(NAS) I/O
    - 성능이라는 관점에서는 대부분의 로컬 디스크는 서너 대의 디스크로 RAID를 구성하고, 캐시로는 서버의 OS 메모리를 이용한다. 이에 비해 외부 저장소는 수십 대에서 수백 대 단위의 디스크를 배치하고, 거기에 캐시 전용 메모리 영역까지 갖추고 있다. 디스크 수에 따라 처리량이 증가하므로 처리량 관점에서는 외부 저장소가 압도럭으로 유리하다.
    - 처리량은 동일 영역을 이용하고 있는 사용자가 많을수록 저하된다. 하나의 RAID 그룹을 독점할 수 있으면 좋지만, 다른 애플리케이션과 영역을 공유하고 있는 경우도 있다. 이것은 OS 및 저장소 설정에 의존하므로 애플리케이션 측면에서 조정이 어려워 주의가 필요하다.
    - 응답속도는 가가우면 빠르다. 단일 응답은 로컬 디스크가 가장 빠르다. 이 차이를 따라잡기 위해서 외부 저장소는 자신이 가진 메모라 영역(또는 SSD 등의 플래시 메모리)을 잘 활용해서 데이터 캐시를 효율적으로 작성함으로써 응답 속도를 개선하는 노력을 하고 있다.
- 순차 I/O와 랜덤 I/O
    - 디스크 I/O에는 순차(sequential) 액세스와 랜덤(random) 액세스가 있다.
    - 순차는 순서를 따른다는 의미로, 선두부터 차례대로 액세스(읽기/쓰기)하느 방식이다.
    - 랜덤 액세스는 헤득 ㅏ움직이면서 해당 위치로 바로 건너뛰는 액세스(읽기/쓰기) 방식이다.
    - 이 두가지는 장기로 말하자면 차와 졸과 같다. 
    - 순차 액세스는 최고속으로 빠르게 회전하고 있는 형태이고, 랜덤 액세스는 항상 해당 부분을 찾고 있는 형태다.
    - 해당 위치를 찾느 것은 대상 위치를 찾아서 바늘(정확히느 actuator)을 움직여야 하기 때문에 시간이 걸린다.
    - 단일 디스크가 기록 위치인 경우는 순차 방식이 빠르고 랜덤은 느리다.
    - 반대로 보통의 데이터베이스 파일에 기록하는 처리는 랜덤 특성을 가지기 떄문에 비효율적이다.
    - 저장 장치 측에서는 큰 파일에 대한 일괄 읽기 처리가 발생하면 다수의 디스크에 대해 동시에 순차 액세스를 한다. 이를 통해 순차 및 병렬로 액세스 할 수있어서 대용량 데이터라도 고속으로 처리할 수 있다.
    - 작은 파일에 액세스하는 경우에는 단일 디스케 랜덤 I/O를 하기 때문에 그다지 빠르지 않다. 때문에 저장 장치 측에서는 앞서 언급한 메로리나 SSD 등 랜덤 I/O에 강한 기억 영역을 이용하여 디스크의 내용을 캐시하는 구조를 적용해서 효율화를 도모하고 있다.
    - 참고로, 순차/랜덤 ㄷ특성은 파일 크기에 의존하지 않는다.

### 네트워크 I/O 병목 현상의 예
- 통신 프로세스의 병목 현상
    - 네트워크 회선에서는 특히 대역이 중시되는 경향이 있다.
    - 하나의 프로세스로 처리하는 경우 높은 처리량을 실현하느 것이 매우 어렵다. 이유는 통신에느느 반드시 데이터 전송, 통신 결과 확인 같은 처리가 포함되므로 항상 풀 파워로 송수신이 이루어지지 않기 때문이다. 또한, 통신이 고속화되면 CPU에서 병목 현상이 발생할 수도 있다.
    - 통신 대역을 모두 사용하려면 처리를 다중화해서 병렬화할 필요가 있다. 다중화 할수록 통신량이 많아지므로 대역폭이 최대치에 가까운 처리량을 시로현할 수 있다. OS나 소프트웨어에 따라서는 이 다중화를 자동으로 구현하고 있는 것도 있다.
    - 압축을 이용해서 전송량을 줄이는 것도 한 가지 접근 방법이 될 수 있다. 단, 이 접근법은 압축 및 해제 시 발생하는 CPU 오버헤드를 감안해야 한다.
- 네트워크 경로의 병목 현상
    - AP 서버에서 클라이언트 PC로, DB 서버에서 AP 서버로 가는 큰 트랜잭션들이 모두 게이트웨이인 특정 라우터를 경유하는 바람에 라우터가 처리 한계에 다다를수 있다. 또한, 사내 여러 시스템과 클라이언트 사이의 게이트웨이 역할을 하고 있었던 것도 원인이었다.
    - 시스템을 신규 구축할 때는 IP 주소가 부족한지만 확인하느 ㄴ것이 아니라 경로와 트래픽 증감에 대해서도 검토하도록 하자.

### 애플리케이션 병목 현상의 예
- 데이터 갱신의 병목 현상
    - 데이터베이스를 이용한 시스템에서 자주 발생하는 것이 특정 데이터에 의조하는 처리가 병목 지점이 되는 것이다.
    - 캐시화. 별도의 서버에 질의를 던져느 것이 병목 지점이 된다면, 더 가까운 장소에 캐시화하는 것이 일반적인 방법이다. 단, 네트워크를 경유하는 질의가 없어지므로 처리 효율이 개선될 수 있지만, 병목지점이라는 것에는 변함이 없어서 근본적인 해결책은 되지 못한다.
    - 레코르를 두 개로 나는 형태.
    - 이런 튜닝은 인프라 담당자 혼자서는 실시할 수 없다. 애플리케이션 자체가 병목 지점인 겨우는 AP 담당자와 인프라 담당자가 협력해서 진행해야 한다.
- 외부 질의의 병목 현상

## 정리
- 성능이 나빠져도 시스템은 동작하겠지만 사용자가 외면할 수도 있다. 성능을 항상 고려해서 만족도 높은 시스템을 만들도록 하자.
