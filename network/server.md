
# Server
하드웨어 장비를 소개하고 그 내부에서 데이터가 어떻게 흐르고 있는지 설명한다.  

## 물리서버
서버는 랙(rack)이라느 것에 장착 된다.  

서버 설치 시 중요한 정보는
- 서버 크기(U)
- 소비 전력(A)
- 중량(Kg)

컴포넌트를 연결하는 선을 버스(bus)라고 한다.  

CPU를 중심으로 생각하면 HDD나 네트워크 인터페이스는 메모리에 비해 멀리 있다.  

## CPU
Central Processing Unit의 약자  
서버 중심에 위치해서 연산을 처리한다.  
CPU는 명령을 받아서 연산을 실행하고 결과를 반환한다.  
명령과 데이터는 기억장치나 입출력 장치를 통해 전달 된다.  
연산은 1초에 10억회 이상 실행할 수 있다.  

현재는 CPU를 코어라고 하며, 하나의 CPU에 여러 개의 코어가 존재하는 멀티 코어화가 진행되고 있다.  
코어는 각자가 독립 된 처리를 할 수 있다.  

명령
- 프로세스 or 사용자 -> 키보드 or 마우스 -> OS -> CPU  
- 키보드나 마우스가 하는 처리를 끼어들기(interrupt) 처리라고 한다.  

## 메모리
기억 영역을 말한다.  
CPU 옆에 위치하며 CPU가 전달하는 내용이나 데이터를 저장하거나 처리 결과를 받는다.  

메모리에 저장되는 정보는 영구성이 없다.(서버를 재시작하면 없어지는 정보이다.)  
메모리를 사용하는 이유는 메모리 액세스가 매우 빠르게 이루어지기 때문이다. 그리고 데이터 저장 시에 물리적인 모터 등을 구동하는 것이 아니라 전기적인 처리만으로도 데이터를 저장하기 때문이다.  

CPU 자체도 메모리를 가지고 있다.  
레지스터나 1차(L1)/2차(L2) 캐시라고 불리며, CPU 내부에 존재한다.  
메모리보다 더 빠르긴 하지만, 용량이 메모리에 비해 매우 작다.  

처리 지연을 줄이기 위해서 가장 자주 사용하는 명령/데이터를 코어 가까운 곳에 배치한다.  
일반적으로 캐시 메모리가 커질수록 액세스 속도가 느려진다.  
초고속으로 액세스하고 싶은 데이터는 L1 캐시에, 고속으로 액세스하고 싶은 데이터는 L2 캐시에 두는 형태로 만든 것이다.  

메모리에는 미리 데이터를 CPU에 전달해서 처리 지연을 줄이는 메모리 인터리빙(memory interleaving)이라는 기능이 있다.  
채널(channel)은 메모리와 CPU 간 데이터 경로를 말한다.  
세 개의 채널을 사용해서 데이터 1을 요구하면 데이터 2와 3도 함께 보내 버린다.  
이것은 대부분의 데이터가 연속해서 액세스된다는 규칙을 기반으로 만들어진 것이다.  
먼저 읽어서 처리 지연을 줄여주는 것이다.  
이 기능을 활용하기 위해서는 모든 채널의 동일 뱅크에 메모리를 배치해 한다.  
CPU의 데이터 처리 속도를 줄일 수 있다.  

## I/O 장치

### 하드 디시크 드라이브(HDD)
기록 영역  
서버에서는 메모리에 비해 CPU에서 떨어진 곳에 HDD가 배치된다.  
주로 장기 저장 목적의 데이터 저장 장소로 사용한다.  
메모리와 액세스 속도가 다르며, 전기가 흐르는지 여부에 따라 데이터가 손실되거나 손실되지 않거나 하는 점이 다르다.  
자기 원반이 여러 개 들어 있으며, 이것이 고속으로 회전해서 읽기/쓰기 처리를 한다.  
CD나 DVD와 같은 구조다.  
회전 구조 때문에 속도가 물리 법칙에 좌우된다.  

최근에 기술이 발달해서 SSD(Solid State Disk, 반도체 디스크)라는, 물리적인 회전 요소를 사용하지 않는 디스크가 사용되고 있다.  

HDD가 많이 탑재돼 있는 하드웨어를 스토리지(Storage, 저장소)라고 한다.  
저장소는 I/O의 서브 시스템이라고도 부리는 장치로서, 내부는 CPU와 캐시가 존재하고 수많은 HDD 외에도 여러 기능을 탑재하고 있다.  

서버와 I/O 시에는 HDD가 직접 데이터 교환을 하는 것이 아니라 캐시를 통해서 한다.  

대형 저장소와 연결할 때는 일반적으로 파이버 채널(Fibre Channel, FC)이라는 케이블을 사용해서 SAN(Storage Area Network)이라는 네트워크를 경유한다.  
SAN에 접속하기 위한 파일 채널 인터페이스를 FC 포트라고 한다. 보통은 서버 시스템 포트에 FC 포트가 없기 때문에 PCI 슬롯에 HBA라는 카트를 삽입한다.  

쓰기 시에 캐시에만 데이터를 기록하고 완료했다고 간주하는 경우 데이터를 잃을 가능성이 있다. 장점은 캐시에 저장해서 쓰기 처리가 종료되기 때문에 고속 I/O를 실현할 수 있다.  
이런 쓰기를 라이트백(write back)이라고 한다.  
대부분의 저장소 제품에서는 이 캐시를별도의 캐시와 미러링해서 안정성을 높이고 있다.  

쓰기 시에 캐시와 디스크를 모두 읽어서 라이트 백과 비교하고, 더 확실 한 쪽에 쓰기 처리를 위해 액세스 한다.  
이 경우 쓰기 캐시의 장점은 없다.  
이런 쓰기 I/O를 라이트 쓰루(write through)라고 한다.  

기본적으로는 캐시의 장점을 살리기 위해 라이트백으로 설정한다.  

### 네트워크 인터페이스
서버와 외부 장비를 연결하기 위한 것으로 외부 접속용 인터페이스다.  
서버 외부 장비로는 네트워크에 연결된 다른 서버나 저장소 장치가 있다.  

### I/O 제어
IA 서버 아키텍처에서 I/O 제어는 I/O 핸들러(IOH) 또는 I/O 컨트롤러(ICH)라느 제어 장치를 통해 한다.  
IOH는 CPU와 가까운 곳에 있어서 노스 브릿지(north bridge)라고 하며, ICH를 사우스 브릿지(south bridge)라고 한다.  

IOH는 이전에는 메모리 I/O 제어가 주요 역할이었지만, CPU에 그 역할이 옮겨 가고 지금은 다른 고속 처리가 필요한 I/O(PCI Express나 네트워크 등)를 제어하고 있다.  
CPU 간 데이터 전송 제어도 한다.  
현재 CPU와 IOH 간에는 퀵 패스 인터커넥트(Quick Path Interconnect)라는 고속 버스로 연결돼 있다.  

ICH는 속도가 느려도 괜찮은 DVD나 USB 등의 I/O 제어를 담당하며, IOH 간 데이터 전송 제어도 한다.  

다른 컨트롤러가 존재하는 이유는 CPU가 해야 할 연산에 더 집중하기 위한 것이라 할 수 있다.  
I/O 시에 관련 처리를 가능한 I/O와 가까운 곳(즉, CPU에서 멀리 있는 곳)에서 처리하는 것이 더 효율적이다.  
즉 CPU와 칩셋의 관계는 역할 분담을 위한 것이다.  

## 버스
서버 내부에 있는 컴포넌트들을 서로 연결시키는 회선을 가리킨다.  

### 대역
원래는 주파수 대역을 가리키지만, IT 인프라에서는 의미가 조금 다르다. 데이터 전송 능력을 의미한다.  
대역은 한 번에 데이터를 보낼 수 있는 데이터의 폭(전송폭), 1초에 전송할 수 있는 횟수(전송 횟수)로 결정 된다.  
전송 횟수는 1초 / 1 처리당 소요 시간(응답 시간)으로 표현할 수 있다.  
대역은 스루풋(throughput, 처리량)이라고도 부른다.  

### 버스 대역
CPU와 메모리는 대량으로 데이터를 교환해서 매우 빠른 전송 능력이 요구되기 때문에 CPU 바로 앞에 위치하고 있다.  
반대로 USB 포트는 60MB/S 전송 능력을 규격으로 저속이기 때문에 ICH 앞에 배치해도 문제가 없다.  

버스 흐름에서 중요한 것은 CPU와 장치 사이에 병목 현상이 없어야 한다는 것이다.  
병목 현상(bottleneck)은 데이터 전송이 어떤 이유로 막혀 있는 상태를 의미한다.  

시스템 설계 시에 특히 놓치기 쉬운 것이 외부 장치 연결 시의 버스 대역에 관한 것이다.  

버스, 대역을 고려해서 시스템에 병목 현상이나 낭비가 발생하지 않도록 설계하는 게 중요하다.  

## 불사조 InfiniBand
인피니밴드는 2000년경에 등장한 기술로, 시스템 버스로 사용되지 않고 시스템 간 고속 인터페이스로 사용됐다.  
HPC 클러스터처럼 여러 노드를 이용한 병렬 처리 솔루션으로 오랫동안 사용돼 온 규격이다.  
저가화가 진행 되면서 IA 서버 간 통신에도 이용되고 있다.  
이더넷을 대신할 고속 통신 규격으로 다시 주목을 받고 있다. 
InfiniBand는 이더넷에서 사용하는 NIC 대신에 HCA(Host Channel Adapter)라는 어댑터를 이용해서 통신한다.  
프로토콜에는 SDP, RDMA를 이용한 SRP 프로토콜, TCP/IP를 처리하는 IPoIB(IP over IB) 등 다양한 프로토콜이 있다.  
전송폭은 10GBps~56GBps로 10G 이더넷 능력을 뛰어넘는다.  
구체적으로 가상화 기술을 이용해서 서버 집약을 한 경우와 대용량 네트워크 전송이나 데이터베이스 서버 간 캐시 전송에 이용된다.  
IPoIB 부분이 InfiniBand와 이더넷의 차이를 흡수하기 때문에 애플리케이션 측에서 동일하게 사용할 수 있음을 알 수 있다.  

---
참조 : [그림으로 공부하는 IT 인프라 구조](https://book.naver.com/bookdb/book_detail.nhn?bid=9252940)
