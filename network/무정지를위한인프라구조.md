
# 무정지를 위한 인프라 구조

## 안정성 및 이중화
- 안정성, 고가용성이란, 시스템 서비스가 가능한 멈추지 않도록 하는 것을 말한다.

### 안정성, 고가용성 목표 => 실현수단
- 고장, 장애에 의한 정지가 발생하지 않을 것(하드웨어서는 MTBF라고 한다.) => 컴포넌트 이중화
- 고장, 장애가 발생해도 복구할 수 있을 것(하드웨어에서는 MTTR이라고 한다.) => 컴포넌트 이중화
- 고장, 장애가 발생한 것을 검출할 수 있을 것 => 컴포넌트 감시
- 고장, 장애가 발생해도 데이터가 보호 될 것 => 데이터 백업

### -
- 상용 웹 시스템에서는 ㅇ미들웨어 기능이나 구조로 이중화, 감시, 백업 세 가지 수단을 구현해서 폭표를 실현한다.

### 이중화란?
- 하나의 기능을 병렬로 여러 개 나열해서 하나에 장애가 발생해도 다른 것을 이용ㅇ해서 서비스를 계속할 수 있느 것을 가리킨다.
- 하나의 기능이 병렬로 가동되기 때문에 이런 고가용성에 대한 의미뿐만 아니라 확장성이나 부하분산 같은 성능에 대한 의미도 가진다.

- 모두가 균등하게 가마를 들 수 있는 구조(부하분산)
- 넘어진 사람이 있는지 정기적으로 확인하는 구조(내부적 생존 감시)
- (보충 요원이 있는 경우)스모 선수를 운반하는 사람이 누구인지 판단하는 구조(마스터 결정)
- (보충 요원이 없는 경우)안전한게 요원을 교체할 수 있는 구조(페일오버)

#### 장애보호
- 물리 장애는 H/W(하드웨어) 장애이고, 논리 장애는 데이터 장애다.
- 물리 장애 보호 범위
  1. H/W 컴포넌트 자체 수준의 장애
    - 서버 내 자원이나 팬 자체의 장애를 가리킨다.
    - 이 장애에 어느 정도 견딜 수 있는가를 보여주는 지표가 신뢰성이다.
    - MTBF 값으로 측정한다.
  1. 시스템 서비스 수준의 장애
    - 하나의 서버가 다운되는 장애를 가리킨다.
    - 이 장애에 어느 정도 견딜 수 있는가를 보여 주는 지표가 가용성이다.
    - 이를 위한 대책 중 하나가 이중화다.
  1. 사이트 수준의 장애
    - 데이터 센터의 정전이나 대규모 재해로 인해 발생하는 장애를 가리킨다.
    - 이 장애애에 어느 정도 견딜 수 있는가를 보여 주는 지표가 사업 연속성이다.
    - 이를 우한 대책에는 장애 발생 시의 인원 확보 계획이나 대체 업무 준비, 시스템 지속이나 데이터 보호 검토가 포함된다.
    - 시스쳄 지속이나 데이터 보호 솔루션을 일반적으로 Disater Recovery(DR, 재해 복구)라고 한다.
- 논리 장애의 보호 범위는 거의 비슷하며, 대책으로는 백업이 있다. 저장소 기능 중 하나인 스냅샷은 데이터 복제를 하지 않고 과거 데이터를 참조할 수 있는 논리 백업으로, 진짜 백업이라고 보기는 어렵다.
- DR은 데이터 원격 백업 성격을 가지고 있기 때문에 백업과 비슷하지만 대책 목적이 사이트 장애다.

## 서버 내 이중화

### 전원 장치 등의 이중화
- 랙 뒤쪽의 양 끝에는 전원 탭이 붙어 있다. 양 끝에 있는 이유는 이중화 때문이다.
- 대규모 데이터 센터에서는 각 정원 탭이 별도 분전반이나 UPS(정전 시에 이용하는 대규모 충전지)에 접속돼 있어서 전원 장애에 대비하고 있다.
- 한쪽 전원 탭의 전략만으로 서버가 가동될 수 있도록 소비 전력 합계를 낮추는 것이 중요하다.

### 네트워크 인터페이스 이중화
- PCI 슬롯에 꽂은 카드도 이중화가 가능하다. 네트워크 인터페이스나 파이버채널(FC)포트(케이블 꽂는 곳)에는 이중화 기능이나 이중화를 실현하는 소프트웨어가 있다.
- 네트워크 인터페이스 이중화는 하드웨어 또는 OS로 구현한다.
- 액티브-스탠바이 구성은 마스터-슬레이브 개념에 기반한 것으로, 스탠바이 측은 보통 서비스를 제공하지 않는다. 액티브 측에 어떤 문제가 발생하면 스탠바이 장비로 교체돼서 스챈바이가 액티브로 변경된다. 이렇게 교체ㅏ는 것을 페일오버(failover)라고 한다.
- 네트워크 인터페이스 이중화의 대표적인 구현 방법 중 하나인 리눅스 OS의 본딩(bonding)은 액티브-스탠바이 구성은 액티브-백업이라고 한다. 어떤 인터페이스가 마스터가 되는지는 설정에서 지정할 수 있다.
  - 본딩이 이중화된 인터페이스를 감시하는 방법에는 두 가지가 있다.
    - MII 감시는 MII(Media Independent Interface) 규격에 준거한 인터페이스의 링크 감시로, 현재 주류로 자리잡고 있는 감시 방식이다. MII 검사에서는 링크업(인터페이스가 가동되는 것)이 동작하고 있다면 정상이라고 판단한다.
    - MII 감시가 선호되는 주된 이유
      - 불필요한 폴링 패킷이 전소되지 않는다.
      - 폴링 위치로 지정한 IP 주소를 가진 장비에 대해서는 유지관리나 장애를 의식하지 않아도 된다.
    - ARP 감시는 특정 IP 주소로 ARP 요청을 보내서 돌아오는 응답 유무에 따라 정상적인지를 확인하는 방법.
      - ARP 감시로만 인지할 수 있는 장애도 있다. 임의의 IP 주소에 대해 ARP 요청을 보낼 수 있다. 주로 네트워크 게이트웨이로 요청을 보낸다. 결과적으로 범위가 정상적인지 확인 할 수 있다. 반면에 MII 감시는 인터페이스의 링크 상태를 확인하기 때문에 접소괘 있는 L2 스위치만 감시할 수 있다. APR 감시가 더 넓은 범위를 감시한다는 것을 알 수 있다.
      - ARP 감시에서는 ARP 요청을 정기적으로 실행해서 응답이 있으면 정상이라고 판단한다.
      - ARP 요청은 MAC 주소를 확인하는 브로드캐스트다. 레이어2에서 실시된다.
      - ARP 요청의 단점은 폴리이 되는 ARP 요청이 동일 네트워크 내의 브로트캐스트이기 때문에 불필요한 트래픽이 증가한다는 것이다. 따라서 이 불필욯란 트패픽을 고려해서 감시 빈도를 너무 높게 설정하지 않는 것이 중요하다. ARP 감시는 일반저긍로 1~2초 간격으로 1~2초 간격 정도로 설정한다.(참고로, MII 감시는  0.1 ~ 0.5 정도의 간격으로 설정하는 것이 일반적이다.)
    - 페일오버 구조는 감시 방법에 상관없이 동잉하다.
      - 인터페이스가 페일오버하면 스위치의 MAC 주소 테이블이 변경되고 통신이 재개된다. 이와 같이 네트워크 인터페이스 이중화인 본딩의 구현은 L3 네트워크 계층보다 낮은 계층에서 구현되고 있다. 때문에 장치 이중화 기능이 L7 애플리케이션 계층에서 구현돼 있으면 이상하다라고 판단할 수 있는 감각이 필요하다.

## 저장소 이중화
- 저장소 이중화의 주요 대상은 HDD다.
- 컨트롤러에는 CPU나 캐시가 있어서 HDD I/O 제어를 하고 있다. 실제 HDD는 전용 상자(엔클로저(enclosure)나 쉘프(shelf)라고도 한다)에 담겨 있어서 증설이 용이하다.
- 최근에는 서버와 저장소 사이를 파이버 채널(FC)로 연결하는 SAN(Storage Area Network)이라는 네트워크 구성이 사용되고 있다.
  - SAN에서는 IP 주소 대신에 WWN(World Wide Name)이라는 주소를 이용해서 데이터를 전송한다.
- HDD를 서로 연겨하는 내부 버스를 최근 들어 SAS(Serial Attached SCSI)방식으로 바뀌고 있다.
  - 각 장비에 IN과 OUT 포트가 있어서 계속 따라가다 보면 HDD까지 원형 연결이 만들어지는 것을 알 수 있다.
  - 저장소는 이 원형 연결을 여러 개 준비해서 HDD 액세스 이중화를 도모하고 있다.
- 서버가 저장소를 액세스할 때는 일반적인 액티브-스탠바이 또는 액티브-액티브 방식을 이용한다.
- RAID는 여러 HDD를 묶어서 그룹으로 만들고 이것을 논리적인 HDD로 인식하는 기술이다.
- 논리적 HDD를 LU(Local Unit)라고 한다. 서버가 인식하는 HDD는 이 LU다.
  - RAID 장점
    1. 안정성 확보
      - 데이터 기록을 이중화한다. HDD는 움직이는 부분이 많아서 쉽게 고장 난다. 띠라서 기록 장치를 이중화한다는 것은 매우 중요한 의미를 가진다.
    1. 성능 향상
      - RAID 컨트롤러가 미리 정해 놓은 길이(8KB, 16KB, 32KB 등)로 I/O를 분할해서 복수의 HDD에 대한 병렬로 I/O를 처리를 한다.
      - 이 고정 길이를 RAID의 스트라이프(stripe) 크기라고 부른다.
      - 여러개의 HDD를 병렬로 동시에 동작시키기 때문에 하나의 HDD를 동작시킬 때보다 I/O 처리 성능이 높아진다. 이 특성을 살리려면 하나의 RAID 그룹에 포함하는 HDD수를 늘리면 된다. 대신에 한대의 HDD 고장이 끼치는 영향 범위도 커지기 때문에 상충 관계에 있다고 할 수 있다. 최근에는 I/O 성능 중시 경향이 있어서 하나의 RAID 그룹 크기가 커지고 있다. 8대 ~ 15대 정도가 하나의 그룹을 이룬다.
      - 참고로 RAID 스트라이프의 크기의 최댓값은 해당 시스템의 I/O 측성, 저장소 종류에 따라 달라질 수 있으니 제조사에 문의하도록 하자.
    1. 용량 확장
  - RAID 구성 패턴(RAID1, RAID5, RAID1+0과 같은 구성 패턴이 주류다.)
    - RAID5
      - RAID5는 이중화 확보를 위해 패리티라는 오류 수정 부호를 기록한다.
      - 패리티를 하나의 HDD에 집중시키지 않고 분석하는 것이 특징이다.
      - 패티리 연산이 이루어지기 때문에 RAID1+0에 비해 I/O 성능이 느리다.
      - 이중화 부분이 적고(HDD수 - 1) / HDD 수만큼의 용량을 사용할 수 있다. 용량을 중시하는 경우는 RAID5를 사용하는 것이 좋다.
    - RAID1, RAID1+0
      - RAID1은 일반적으로 OS 디스크 이중화에 사용된다.
      - RAID1+0은 RAID0과 RAID1을 조합한 구성이다. RAID0은 이중화 없이 HDD에 기록하는 방식이다. RAID1+0은 복수에 HDD에 병렬로 이중 기록을 하는 방식이다. 이것은 안정성과 성능을 균형 있게 구성하는 방식이다.
      - 미러링을 하기 때문에 전체 용량의 1/2 용량밖에 사용할 수 없다.
      - HDD가 고장나면 RAID 구성에 포함된 데이터는 망가지지 않지만, 이중호화 구조가 망가진다. 이 이중화 회복을 위해 핫 스페어라고 하느 디스크를 이용한다. 한대의 HDD가 고장 남녀 자동적으로 핫 스페어가 RAID에 포함돼서 이중화 구조를 회복한다. 하지만 핫 스페어가 고갈되고 거기에 HDD까지 파손된 RAID에서는 데이터 손실이 발생하기 때무에 주의가 필요하다.
    - 이와 때문에 RAID에 의존하는 것이 아니라 데이터 백업도 반드시 해 두어야 한다.
  스의 이중화
- 저장소 이중화 대상에는 서버와 저장소 사이에 있는 버스도 있다.
- 버스 이중화에서 고려해야 할 것은 장애 시의 교체 시간이다. 일반적으로 장애라고 판단하기까지의 HBA 타임아웃 값은 30초 정도로 설정돼 있다. 실제 장애 발생 시에는 페일오버 타임아웃 시간 동안 저장소 I/O가 정지되기 때문에 이것이 처리에 영향을 끼치는 경우에는 값 단축을 검토해야 한다. 이것은 HBA 파라미터로 설정을 변경할 수 있다.

## 웹 서버 이중화

### 웹 서버의 서버 이중화
- 소프트웨어 관점에서의 서버 이중화
- 클라이언트의 http 프로토콜 요청을 받는 것은 웹 서버어에서 동작하고 있는 웹 서버 프로그램이다. 
- 클라이어트 관점에서는 서버 측이 프로세스로 가동되고 있는지, 스레드로 가동되고 있는지를 의식할 필요는 없다.
- 아파치에서는 어느쪽이든 미리 여러 개를 가동시켜 두어서 클라이언트 요청에 빠르게 대응할 수 있는 구성을 가지고 있다. 여러 개를 가동시켜 두면 프로세스/스레드 중 하나에 장애가 발생해도 다른 프로세스/스레드가 가동되고 있기 때문에 웹 서버의 서비스 전체가 정지되는 일은 없다.
- 일반적으로 상용 시스템은 시스템 리소스에 여유가 있으면 가동 프로세스/데몬 수의 최솟값, 최댓값이 같다. 동일 갑승로 하면 프로세슷낭 스레드의 가동.정지 오버헤드를 줄일 수 있다.
- 장애가 발생하게 되면 httpd는 400번대, 500번대가 일반적인 에러에 해당한다. httpd 프로세스/스레드가 요청을 받을 수 없는 경우는 서버 측 문제이기 때문에 500번대 에러를 클라이언트에게 반환한다.

### 서버의 이중화
- 하나의 DNS를 이용해서 하나의 호스트명에 대해 복수의 IP 주소를 반환하는 것이다.
- 그 중 하나의 방법이 DNS 라운드 로빈(round robin)이라고 한다. 호스트에 대해 복수의 IP 주소를 등록해 두는 것으로서 서버 이중화 기법 중 하나다. DNS는 질의의 순서대로 IP 주소를 반환한다.
  - 첫번째 DNS 서버 상태를 감시해서 파악하지 않기 때문에 서버가 정지된 경우에도 이 서버의 주소를 반환한다. 이 때문에 가용성을 중시하는 경우에는 부적합하다.
  - 두 번째는 DNS가 세션 상태를 파악하지 않기 때문에 다음 접속 시에 동일 서버에 접속해야 하는 경우에도 부적합하다. 

#### 부하분산 장치를 이용한 웹 서버 이중화
- 세션 유지를 위한 방법에는 여러 가지가 있찌만, 부하분산 장치가 이전에 어느 웹 서버에 요청을 할당했는지를 쿠키에 저장하고 있다. 부하분산 장치는 임시 대응 관리표로 세션 테이블이라는 것을 만든다. 클라이언트에 요청을 반환할 때는 이 테이블을 참조한다.
- 세션 상태 저장을 실현하는 기능을 부하분산 장치에선느 퍼시스턴스(persistence, 지속성) 기능이라고 한다.

|퍼시스턴스 종류|내용|
|소스 IP 주소|클라이언트 IP 주소를 기반으로 요청을 할당할 웹 서버를 결정한다.(클라이언트 IP 끝자리가 홀수이면 웹 서버 1에 할당하는 등)|
|쿠키|HTTP 헤더 내에 접속한 웹 서버 정보를 저장한다|
|URL|URL 구조 내에 접속한 웹 서버 정보를 저장한다|

- 출발지 IP 주소를 이용한 퍼시스턴스는 프록시(proxy)를 경유하면 프록시 서버의 IP 주소가 클라이언트 IP 주소가 돼서 요청이 한쪽으로 몰릴 수 있다.
- 쿠키를 사용하는 경우는 각 AP 서버 등이 쿠키를 사용할 때 부하분산 장치가 부여한 쿠키르 ㄹ덮어쓰기 하지 않는지 확인해야 한다.
- URL 정보를 심는 경우, URL은 사용자가 직접 편집 가능한 정보이기 때문에 부정 접속에 대한 대책을 검토해 두어야 한다. 일반적으로는 해시 함수를 이용해서 변경한 값을 심는다.

|알로리즘|내용|난이도|
|라운드 로빈(round robin)|서버의 IP 주소에 순서대로 요청을 할당한다|단순|
|최소 연결(least connection)|현재 활성 세션 수보다 세션 수가 가장 적은 서버의 IP 주소에 요청을 할당한다|중간|
|응답 시간(response time)|서버의 CPU 사용률이나 응답 시간 등을 고려해서 가장 부하가 적은 서버의 IP 주소에 요청을 할당 한다|복잡|

#### 장애가 발생하면 어떻게 되나?
- 부하분산 장치는 웹 서버의 가동 상태를 감시할 수 있다.
- 장애를 감지한 경우는 클라이언트 요청을 동적으로 다른 서버에 할당(페일오버) 할 수 있다.
- 정적 콘텐츠라면 클라이언트는 아무것도 의식하지 않아도 된다. 하지만 동적 콘텐츠라면 페일오버와 세션 정보가 사라지기 때문에 세션 상태가 초기화 된다.
- 할당 알고리즘 선택 시에 고려해야 할 것은 복잡한 알고리즘은 피하는 것이다. 복잡할수록 데이터가 알고리즘을 통과할 때 높은 부하가 발생한다.
- 정적 콘텐츠가 저장되는 웹 서버의 경우에는 일반적으로 웹 서버 처리를 가볍고, 세션 수와 CPU 등의 리소스 소비가 비례하기 때문에 단순한 알고리즘인 라운드 로빈이나 최소 연결 방식 등을 주로 사용한다.
- 부하분산 장치는 고가 장비이기 때문에 IP:포트(L4)나 IP:포트/URL컨텍스트(L7)를 이용해서 어떤 서버에 리디렉션할지를 정밀하게 설정항는 기능 등도 제공한다.

##### DSR(Direct Sever Return)
- 부하부산 장치를 사용한 고급 기술인 DSR
- 부하분산 장치가 요청을 할당하지만, 응답은 부하분산 장치를 경유하지 않고 상위 네트워크 장비에서 직접 반환하게 된다. 이 구성의 장점은 부하분산 장치를 경유하지 않고 고속으로 응답을 반환할 수 있다는 것꽈 부하분산 장치의 처리 부하를 경감시킬 수 있다. 따라서 대량의 요청을 처리하는 데 적합하다.
- 부하분산 장치의 L7(쿠키, URL 등) 부하를 분산할 수 없다는 것에 주의해야 한다. 서버 응답이 부하분산 장치를 경유하지 않으므로 쿠기/URL 등의 정보를 참조할 수 없기 때문이다. 

## AP 서버의 이중화

### 서버 이중화
- AP 서버 이중화는 두 가지 기능을 이용해서 구현한다.
  - 첫 번째는 웹 서버와 같이 부하분산 장치를 이용한다. AP 서버가 가진 웹 서버 요청 이중화 기능을 이용해서 AP 서버 요청을 분산 시키는 것이다.
  - 두 번째는 세션 정보 이중화다. 자바를 실행하는 AP 서버에서는 세션 정보 이중화 기능을 갖추어져 있다. 요청 분산, 세션 정보 이중화의 두 가지 기능에 의해 AP 서버가 이중화 된다. 또한 AP 서버 내 이중화도 이 두가지 기능을 이용해서 구현 되고 있다.
  - 웹로직에는 리다이렉션용 플러그인이 있어서 웹 서버에 구현된다. 세션 저보는 접속된 AP 서버를 기본으로 하고 보조 세션을 복사해 둔다(복제). 이 서버 정보는 쿠키에 저장돼서 클라이언트에게 반환된다. 클라이언트가 재접속할 때 서버에 구현된 리디렉션용 플러그인이 기본 서버를 판별해서 해당하는 AP 서버에 요청을 리디렉션 한다.

#### 장애가 발생하면 어떻게 되나?
- 쿠키 정보를 가지고 보조 세션 정보에 접속해서 세션이 계속 유지되는 것을 알 수 있다. 참고로, 세션 정보를 복제하면 이를 위한 메모리나 네트워크 리소스 소비량이 늘어나기 때문에 주의가 필요하다.

### DB 연결 이중화
- AP 서버에서는 DB 서버에 접속 시에 사용할 연결을 사전에 여러 개 생성해 두는 기능이 있다. 이것을 연결 풀링(connetion pooling)이라고 하며, 웹로직의 데이터 소스를 설정해서 이용한다.
- 원래 데이터 소스는 여러 연결을 만들어서 데이터베이스 처리를 병렬로 실행할 수 있게 하는 구조다. 데이터 소스를 이용하는 장점은 애플리케이션이 DB 서버의 IP나 포트 등을 몰라도 된다는 점이다. 애플리케이션은 데이터 소스명만 알면 된다. 
- 애플리케이션은 연결 해제를 하지 않는다. 따라서 연결 생성 및 해제 시에 걸리는 시간이나 리소스가 필요 업어서 고속으로 처리가 가능하다. 연결 풀링은 기술적 진보가 빨라서 웹로직은 물론 오라클 DB에도 다양한 기능이 등장하고 있다.

#### 장애가 발생하면 어떻게 되나?
- 설정 최댓값까지 연결 수가 늘며, 최댓값을 초과한 요구가 오면 일정 시간 대기한다. 파라미터는 연결 예약 타임아웃이다. 이 경계 값까지 대기한 후 에러를 반환한다.
  - 최솟값과 최댓값을 동일하게 설정한다.
    - 이것은 웹 서버의 httpd 프로세스/스레드에서 설명한 이유와 동일하다. 여결을 생성 하거나 제거할 때 발생하는 오버헤드를 가능한 한 경감시키기 위해서다. 이와 같이 설정하면 연결 오버헤드를 초기 가동 시에만 집중시키는 것이 가능하다.
  - 방화벽 유무를 확인해 둔다.
    - 중간에 방화벽이 있다면 오랫동안 사용하지 않은 세션을 자동으로 제거하는 경우가 있기 때문에 방화벽 유무를 확인해 두어야 한다. 연결 돼 있는 동안 소켓은 Establish 상태이지만, 실제 데이터 교환이 없으면 중간의 네트워크 장비는 해당 연결을 대기 상태라고 간주한다. 특히 방화벽에서는 보안상의 이유로 장시간 대기 상태인 연결을 절단하는 기능이 있다. 이 떄문에 의도하지 않은 절단이 발생하 수 있어서 정기적으로 폴링하는 등 미리 대책을 마련해 두어야 한다. 이런 곳에서도 퐇ㄹ링이 사용되고 있는 것이다.

## DB 서버의 이중화

### 서버 이중화(액티브-스탠바이)
- 액티브-스탠바이형의 클러스터(cluster) 구성
- 클러스터 구성은 하드웨어로도 구현할 수 있찌만, 일반적으로 클러스터 소프트웨어를 이용한다.
- 클러스터 구성은 오픈 시스템이 있어서 빠트릴 수 없는 중요한 요소라고 할 수 있다.
- 클러스터 구성은 HA(High Availability, 고가용성) 구성이라고 부른다.
- 클러스터의 노드나 서비스 관계는 마스터-슬레이브 개념을 기반으로 하고 있다.
- 서버가 정상 동작하는지 확인하기 위한 구조로 하트비트(heartbeat)나 투표 장치 같은 기능이 존재한다.

#### 장애가 발생화며 어떻게 되나?
- 클러스터 소프트웨어는 등록된 서비스가 정상 동작하고 있는지 정기적으로 확인한다. 이상이 발생하면 서비스를 정지하고 대기하고 있던 스탠바이 측 서비스를 시작해서 서비스를 유지시킨다. 일반적으로 십여 분 정도의 정지 시간으로 서비스를 재개할 수 있다.
- 클러스어 소프트웨어는 하트비트를 이용해서 상호 간에 상태를 확인한다. 이 때문에 하트비트를 통해 상태를 인식할 수 없게 되면, 클러스터 소프트웨어는 패일 보어 실시 여부를 판달할 수 없게 된다. 이 상태를 스플릿 브레인(split-brain)이라고 한다. 스프릿 브레인 시에는 빠른 것이 승리. 3노이 이상의 클러스터에서는 다수결이다. 이와 같이 투표 장치는 하트비트 기능을 보완하는 역할을 한다.

#### 클러스터 구성용 서비스란?
- 클러스터 소프트웨어를 이용한 액티브-스탠바이 구성은 서비스르 병렬로 실행할 수 없고 데이터 일관성을 중시하는 서비스/시스템에 적합하다.
- 클러스터 소프트웨어를 이용할 때 주의할 점은 클러스터 소프트웨어도 OS에서 실행되는 소프트웨어이기 때문에 오동작할 가능성이 있다는 것이다.

### 서버 이중화(액티브-액티브)
- DB 서버의 데이터 참조, 갱신 부분은 시스템의 병목 지점이 되기 쉬워서 항상 높은 확장성이 요구된다.
- 쉐어드 에브리씽형(shared everything) : 디스크, 데이터를 모든 노드가 공유한다. 장애가 발생해도 다른 노드로 쉽게 처리를 계속할 수 있다.
  - 쉐어드 에브리씽형에서는 다른 노드에 있는 메모리 데이터의 일치성을 확장할 필요가 있기 때문에 노드 수를 늘려도 확장이 쉽지 않다.
  - 모든 노드가 같은 데이터에 액세스할수 있지만, 이 경우 서로 배타적 제어나 데이터 경합을 하기 때문에 처리 속도가 저하된다.
- 쉐어드 낫씽형(shared nothing) : 각 노드별로 디스크를 가지고 있어서 데이터가 분산된다. 노드를 배치하기 더 쉽다.
  - 대량의 데이터를 검색하는 경우는 데이터가 분산돼 있기 때문에 쉐어드 낫씽형 쪽이 유리하다.
  - 작은 트랜잭션이 대량으로 발생하는 경우도 노드 추가를 쉽게 확장 할 수 있기 때문에 쉐어드 낫씽형이 유리하다.
  - 확장 시에는 데이터 재배치를 검토 및 설계해야 하기 때문에 확장이 쉽지 않다.
  - 갱신 시에 데이터 분산 위치를 검토하기 때문에 전반적인 갱신 처리가 느려지는 경향이 있다.
- 가용성 면에서는 쉐어드 애브리씽형이 어떤 노드에서건 같은 데이터에 액세스할 수 있기 때문에 유리하지만, 쉐어드 낫씽형에서도 데이터 복제 기능을 이용해서 안정성을 고려한 데이터 베이스를 사용할 수 있다. 이처럼 어느 한쪽이 빠르다고 대답하기 어렵다. 시스템에 특성에 따라 해당 시스템의 병목 현상이나 장애 시 영향 등을 고려하은 것이 중요하다고 할 수 있다. 또한, 이론상으로는 이런 문제들이 있지만, 각 제품별로 해당 아키텍처의 단점을 보완하기 위해 여러 노력을 하고 있다. 따라서 아키텍처 선정 시에는 이런 약점을 보완하는 구조도 확인해야 한다.

#### 캐시 전송
- 캐시 퓨(cache fusion) : 캐시의 데이터를 네트워크 경유로 받아서 디스크 액세스를 줄이고 데이터 취득을 고속화하고 있다.
- 캐시 퓨전의 주의할 점은 디스크 액세스보다 빠르지만, 핑퐁처럼 같은 블록이 몇번이고 네트워크를 통해 교환되는 경우에 응답 속도가 저하된다는 점이다. 이것을 블록 경합이라고 한다. 시스템 리소스에 여유가 있지만, 응답 속도가 느린 경우는 이 블록 경합을 의심해야 한다.
- 캐시 퓨전 동작을 보장하기 위해서 최신 블록이 어느 노드에 저장됐는지 관리하는 구조가 있다. 베타적 제어는 이 구조에 의해 이루어진다.
- 쉐어드 에브리씽형 데이터베이스에서는 설계가 제대로 돼 있어도 캐시 퓨전에 사용되는 병목 지점이 되기 쉽다. 이 문제를 해결하기 위해 연결에 이더넷이 아닌 InfiniBand라 불리는 대역이 큰 전송 네트워크를 이용하는 경우도 있다.
- 데이터 보호는 데이터 노드 간 복제 기능에 의해 구현된다. 데이터 노드의 데이터가 동일 노드 내 정/부로 복제되며, 다른 데이터 노드에도 복제된다. MySQL 클러스터는 이와 같이 쉐어드 낫씽이지만 장애 시 데이터 보호도 가능하다. 단점은 데이터 교환을 위해 네트워크 리소스와 디스크 용량을 소비한다는 것이다.

## 네트워크 장비 이증회

### L2 스위치 이중화
- 스위치를 크로스 케이블 등(MDI-X가 구현돼 있으면 스트레이트 케이블도 괜찮다)으로 연결하면 서로 다른 스위치 간 통신이 가능하다. 이것을 캐스케이드(cascade)라고 한다. 하지만 최근에는 하나의 스위치를 하나의 네트워크에서만 이용하는 것이 아니라 복수의 네트워크에 연결하는 경우도 있다. 이런 경우에는 스위치가 복수의 VLAN을 설정한다.
- 스위치 간에 VLAN 통신을 할 때는 각각의 VLAN을 연결해야 한다. 하지만 트렁크 포트를 이용한 포트를 복수의 VLAN에 소속시킬 수 있다. 이런 방식으로 트렁크 포트를 사용하는 것이 주류가 되고 있다.
- 트렁크 포트를 사용하려면 VLAN 데이터를 식별할 수 있도록 설정해야 한다. 최근에는 IEEE802.1Q로 표준화된 VLAN 태그 기술이 자주 이용되고 있다.

#### 트렁크 포트 이용 시에 필요한 대책
- 네트워크 이중화 중 링크 집한(link aggregation)이란 게 있다. 서버나 NAS 등에서는 여러 포트를 합쳐서 하나의 이너넷 포트로 이용할 수 있다. 리눅스의 본딩 기능에서도 가능하다. 링크 집합에서는 보통은 양쪽 포트를 사용하지만, 포트 장애 시에는 해체해서 처리를 계속 할 수 있다. 또한, 양쪽 포트를 사용함으로써 대역이 배로 증가하기 때문에 병목 현상 해결책으로도 이용할 수 있따. 일반적으로 최대 4선 정도까지 묶을 수 있다.
- 서버 측 포트를 묶는 경우느 꽂고 있는 스위치 쪽 포트도 걑은 방식으로 묶어야 한다. 시스코 스위치에서는 이 기능을 이더 채널(EtherChannel)이라고 부른다. 이더 채널에서는 트렁크 포트도 묶을 수 있다. 트렁크 포트는 이 기능을 이용해서 여러 포트를 묶어 사용함으로써 트렁크 포트 통신이 병목 지점이 되는 것을 방지하고 안정성을 놏일 수 있다.
- 대역 확장을 목적으로 웹 서버의 인터페이스를 링크 집한 한다고 해도 인터넷의 출입 회선이 웹 서버의 인터페이스 회선보다 좁다면 병목 현상 제거 효과를 기대할 수 없다.
- 일반적으로 링크 집합은 트렁크 포트, NAS 접속 인터페이스 등에 이용한다. 링크 집합 검토가 유용하긴 하지만, 네트워크 대역을 검토할 때는 통신 출발지와 목적지 사이에 있는 몯느 대역을 고려한 후 병목 지점을 찾아서 문제를 해결하는 것이 중요하다.

### L3 스위치 이중화
- L3 스위치 이중화는 기본적으로 액티브-스탠바이다. 최근 시스코 등에서 액티브-스탠아비에 이용할 수 있는 Virtual Switching System(VSS)과 같은 기능도 제공하고 있다.
- L3 스위치는 스위치 기능과 간이 라우터 기능을 동시에 갖추고 있는 장비이다,. L3 스위치가 L2 스위치로도 사용되고 라우터로도 사용되는 것을 알 수 있다.
- 웹 시스템에서는 게이트웨이가 다운되면 시스템 서비스가 거의 모두 정지된다고 해도 과언이 아니다. 따라서 L3 스위치 이중화가 매우 중요하다. 구체적인 구현 방법으로 L3 스위치의 액티브-스탠바이를 실현하는 프로토콜인 Virtual Router Redundancy Protocol(이후 VRRP)이라는 것이 있다. 

1. 어느 쪽 장비가 기본(마스터 라우터)인지를 정한다.
1. 정기적인 하트비트(애드버타이즈먼트(advertisement))를 보내서 생존 감시를 한다(자신이 살아 있다는 것을 증명)
1. 보조(백업 라우터) 장비가 애드버타이즈먼트를 일정 시간 수신하지 못하면 마스터 라우터 역할을 인계한다.

- VRRP에서는 1의 마스터 라우터 결정에 우선도 값을 사용한다. 큰 값이 마스터가 된다.
- 2의 정기적인 애드버타이즈먼트느 라우터부터 백업 라우터 순서로 수 초 간격으로 진행된다.
- VRRP는 전용 링크가 필요 없다.
- VRRP를 이용하는 VLAN의 경우는 소소된 모든 포트가 생존 감시 대상이 된다. 일반적으로 연결이 끊어지지 않는 것을 전제로 해서 스위치 간 트렁크 포트를 설계한다.

#### 장애가 발생하면 어떻게 되나?
- 페일오버는 애드버타이즈먼트가 실해한 후 일반적으로 수십 초 사이에 교체 된다.
- 백업 라우터가 마스터 라우터로 승격되고 가상 라우터 주소가 이동한다.

### 네트워크 토폴로지
- 복수의 경로가 존재하는 네트워크 구성을 루프(loop)라고 한다. 하지만 경로가 다수 존재하면 안정성 측면에서 좋지 않다. 이 모순을 해결하기 위한 수단으로 스패닝 트리 프로토콜(Spanning Tree Protocol, 이하 STP)이라는 것이 있다.
- STP를 이용하면 논리적으로 포트를 절단 할수 있다(브롤킹 포트라고 한다). 절단할 포트를 STP 계산 알고리즘에 의해 정해지지만, 스위치 설정을 통해 절단 대상을 제어할 수도 있다.
- 장애 시에는 STP에 의한 재계산이 이루어지며, 논리적으로 절단돼 있는 포트를 개통해서 통신이 가능해진다.
- STP 단점은 계산에 최대 50초가 걸려서 장애 발생 시 정지 시간이 길다는 것이다. 현재는 RSTP(Rapid-STP)라는 STP 개선판이 주로 사용돼서 페일오버 시간은 거의 제로에 가깝다.

#### 네트워크 구성의 대표적인 패턴
- 사다리형
- 십자형
- 사다리형, 십자형 모두 STP를 이용해서 블록을 하고 있다.
- 십자형은 1루프에 관여하는 스우치 수가 세 개이며(사다리형은 네 개), STP 계산 알고리즘 조정이 쉽다는 것이 장점이다. 최근에는 십자형이 주로 사용된다.

##### 브로드캐스트 스톰(vroadcast storm)
- 네트워크 구성 시 동일 세그먼트 내에 패킷이 통과하는 경로가 하나가 아닌 복수 개 존재해서 루프하는 경우 발생하는 현상이다.
- 브로드캐스트는 모든 방향으로 전송되기 때문에 이를 받은 스위치는 다시 다른 스위치에 대해 브로드캐스를 보내 통신량이 엄청나게 늘어난다.
- 결과저긍로 네트워크 장비의 CPU 사용률이 높아지며, 다른 네트워크 처리를 받을 수 없게 되어 광범위한 시스쳄 장애를 일으킨다.

## 사이트 이중화

### 웹 사이트 이중화
- 원격지 데이터 센터와 연계하는 기술인 글로벌 서버 부하분산(GSLB)이라는 구조가 있다.
- 화재 대책을 목적으로 한 원격지 데이터 전송 기술을 통틀어서 재해 복구(disater recovery)라고 부르는 경우도 있다.
- 원격지에 데이터를 전송할 때 중요한 것은 동기/비동기 여부다. 완전히 데이터를 지키고 싶을 때는 데이터가 원격지에도 기록될 필요가 있기 때문에 동기화 시킨다. 하지만 이경우네는 데이터를 원격지와 동기화 시킬 때 오버헤드가 많이 걸려서 응답 속도가 느려진다. 비동기라면 응답은 좋지만 데이터를 완전하게 지킬 수 없다.

## 감시

### 감시란?
- 생존 감시
- 로그(에러) 감시
- 성능 감시
- 이외에도 하드웨어 자신이 하드웨어 고장을 감시하거나 클러스터 소프트웨어가 실시하는 각 컴포넌트 감시 등 다양한 감시가 있다.
- 감시에서 중요한 것은 어떤 목적으로 감시 기능이 필요한지, 특정 컴포넌트에 감시가 너무 중복돼 있지 않은지 등을 고려하는 것이다.
- 모든 프로세스를 감시해서 로그가 하나라도 출력되면 그것을 감지할 수 있도록 설정해야 한다. 하지만 실제로 경고가 발생해도 어떤 식으로 대처하면 좋을지, 경고 발생 후 행동으로 연결되지 않는다면 의미가 없다. 또한, 감시 수가 너무 많으면 경고가 전달돼도 무시하게 된다.
- 감시 대상을 선별하는 것은 용기 있는 행동이다.

### 생존 감시
- ping 명령을 정기적으로 실헹헤서 서버 인터페이스에 대한 통신을 확인하는 감시로, ping 감시가 있다.
- ping을 이용한 감시는 구현이 매우 쉬워서 어떤 시스템이라도 구현할 수 있다. ping 감시는 가능한 모든 장비에 설정할 것을 권장한다.
- 대부분의 감시 툴은 프로세스가 정상 동작하는지를 OS의 ps 명령을 이용해서 확인한다. ping처럼 매우 간단한 감시다.
- 프로세스 감시는 실행 중인 프로세스 모두를 감시하는 것이 아니라 중요한 것만 추려서 감시하는 것이 좋다.

### 로그 감시
- OS나 미들웨어가 출력하는 로그 파일에는 시스템 유지를 위한 중요 정보가 포함돼 있다. 미들웨어 오류나 영역 고갈 등 생존 감시로는 알 수 없는 정보가 로그 파일로 출력 된다. 로그 파일 감시에서는 로그 내용을 선별해서 중요한 로그 정보이면 감시 서버에 경고 메시지를 보낸다.
- 로그 감시 프로세스는 중요하다고 인지하고 있는 로그 출력문을 미리 저장해 두고 있다가 실제 로그 파일이 출력되는 내용을 저장해 둔 것과 비교한다. 일치하는 내용이 있으면 문제의 중요도에 맞추어 감시 서버에게 보고한다. 통지 방법은 syslog, SNMP, 메일 등 몇 가지가 있다.
- 대부분의 미들웨어 로그는 \[alert]이나 \[error], \[notice] 등의 문자열을 붙여서 출력한다.

### 성능 감시
- 디스크 사용률이나 메모리 사용 현황, 디스크 고갈 등의 리소스 상태 파악과 네트워크 액세스 지연, 디스크 액세스 시간 등의 응답 상태를 파악하는 것이다.
- df 명령 등의 OS 명령을 정기적으로 실행하거나 vmstat 명령이나 sar 명령 등의 통계 정보를 취득해서 상황을 통계저긍로 판단하는 등 다양한 방식이 가능하다.

|감시 대상|감시 내용|
|CPU|CPU 사용률, CPU 대기 행렬|
|메모리|빈 메모리 양|
|DISK|남은 용량, 디스크 액세스 시간|
|네트워크|I/F 인바운드/아웃바운드 대역 사용률|
|HTTP(웹 서버 고유)|HTTP 요청의 응답 시간, 초당 HTTP 요청 처리 수, 초당 HTTP 세션 수|
|JAVA(AP 서버 고유)|메모리 힙(heap) 크기, 가비지 컬렉션 횟수|
|DATABASE(DB 서버 고유)|영역의 남은 용량, 캐시 사용률, SQL 응답|

### SNMP
- 통합 감시 툴로 상용 제품이 다수 존재하며, IBM의 터볼리 등이 대표적이다. 기능도 다양하지만, 이 기능들을 기반으로 하고 있는 감시 전용 프로토콜이 SNMP이다.
  - 네트워크 장비나 서버 가동 상태
  - 서비스 가동 상태
  - 시스템 리소스(시스템 성능)
  - 네트워크 트래픽
  - SNMP는 네트워크 장비와 서버를 일괄 감시해서 관리할 수 있는 것이 특징이다.
  - SNMP 구성에서는 감시 서버에 매니저가 있으며, 감시 대상 서버 및 네트워크 장비에 에이전트가 존재한다.
  - 감시 경로에는 매니저가 정기적으로 질의하는 폴링과 이상 발생 시에 에이전트가 통지하는 트랩 등 두가지가 있다.
    - 폴링은 주로 리소스 상태를 검사할 때 이용한다.
  - SNMP의 주요 특징으로 MIB(관리 정보 기반)이라는 것이 있다. MIB는 감시 정의 모델이다. 에이전튼느 MIB에 규정된 정보를 수집해서 매니저에게 통지한다. 매니저와 에이전트는 상호 대화를 하기 때문에 같은 MIB를 소유한다.
  - SNMP는 감시에 특화된 프로토콜이다. SNMP를 구현하지 않았을 때는 문제 감지 시 통지 수단으로 메일을 사용할 수 있다. 메일은 축적 및 저장이 용이하지만, MIB 같은 범용적인 정의가 없기 때문에 구현 시 여러 사항을 고려해야 한다.

### 콘텐츠 감시
- 콘텐츠 감시는 웹 시스템 특유의 감시다.
- 일반적으로 콘텐츠 감시는 부하분산 장치가 담당한다.

## 백업

### 백업이란?
- RTO(Recovery Time Objective) :복구 목표 시간
- RPO(Recovery Point Objective) : 복구 기준 시점

- 시스템 백업(OS나 미들웨어 등의 백업)
- 데이터 백업(데이터베이스나 사용자 파일)

### 시스템 백업
- 초기 구축 후
- 일관 처리 적용 시
- 대규모 구성 변경 시

#### 취득 방법
- OS 명령(tar, dump 등)
- 백업 소프트웨어

- 백업은 압축 기능이 유용한 처리다. 
- 시스템 백업 취득 시의 유의점은 서버의 서비스를 정지할 필요가 있다는 것이다. 가동 중인 서비스는 백업할 수 없다.

### 데이터 백업
- 데이터 백업은 시스템 백업과 달리 매일 변경되는 데이터가 손실되지 않도록 하는 것으로, 취득 빈도가 높다. 이 때문에 정지하기 힘든 시스템은 서비스가 가동 중인 상태라도 백업이 가능한 구조가 필요하다.하지만 그런 시스템일수록 데이터 일치성을 보장해야 하며, 특히 데이터베이스 시스템에 있어서는 일치성 보장 기능이 필수다. 이와 같은 사정 때문에 데이터베이스 백업은 데이터 자체와 데이터 갱신 내역이 기록돼 있는 저널을 모두 취득하도록 하고 있다.
- 데이터는 기본저긍로 서비스를 정지한 후 변경이 발생하지 않은 상태에서 취득한다.
- 데이터베이스가 망가진 경우라면 일관성 있는 데이터와 저절 로그 양쪽을 복구한다. 또한, 복구되지 않은 저널 로그가 장애 발생 직전까지 존재한다면 최신 데이터로 복구 할 수 있다.
- 백업 취득 방법은 다양한다.
- 데이터를 백업한 것도 시스템 백업과 마찬가지로 압축하는 것이 좋다.